---
title: "IBM Employee Attrition & Performance"
runtime: shiny
output:
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: fill
    theme: readable
    source_code: embed
    social: menu
    navbar:
     - { title: "Home", 
         href: "https://alecrsf.netlify.app/en/", 
          icon: "fa-home"}
---

```{r global, include=FALSE, message=FALSE, warning=FALSE}
library(flexdashboard)
library(tidyverse)
library(viridis)
library(plotly)
library(highcharter)
library(shiny)

data = read_csv("https://raw.githubusercontent.com/alecrsf/dataset/main/IBM-HR.csv",
								col_types = cols(
									Attrition = col_factor(),
									Gender = col_factor(),
									EducationField = col_factor(),
									MaritalStatus = col_factor(),
									JobRole = col_factor(),
									BusinessTravel = col_factor(),
									Department = col_factor(),
									Education = col_factor(),
									EducationField = col_factor(),
									EmployeeCount = col_skip(),
									EmployeeNumber = col_skip(),
									OverTime = col_factor(),
									JobRole = col_factor(),
									Over18 = col_skip(),
									OverTime = col_skip(),
									StandardHours = col_skip()
								))

Categorical.Variables = c("Gender", "Department", "EducationField", "MaritalStatus", "JobRole", "Attrition")
Numeric.Variables = c("MonthlyIncome", "HourlyRate", "DistanceFromHome", "EnvironmentSatisfaction","JobInvolvement","JobSatisfaction", "NumCompaniesWorked", "RelationshipSatisfaction", "TotalWorkingYears","YearsSinceLastPromotion","PercentSalaryHike", "YearsAtCompany", "Age")

theme = ggthemes::theme_hc() + 
	theme(plot.caption = element_text(hjust=0, 
																		size=8),
        plot.title = element_text(hjust = 0, 
        													size=12, 
        													face="bold"),
				axis.ticks = element_blank(),
        axis.title.x = element_text(size=10),
        axis.title.y = element_blank())  
```

# Exploratory Analysis {data-navmenu="HR Analytics"}

## Column {.sidebar data-width="250"}

[**IBM Employee Attrition & Performance**]{style="color: #2A5676;"}

The aim is to predict attrition of valuable employees and explore important questions such as 'show me a breakdown of distance from home by job role and attrition' or 'compare average monthly income by education and attrition'. This is a fictional data set created by IBM data scientists and it is possible to download it from [Kaggle](https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset){style="color: #2A5676;"}.

```{r input}

selectInput(
	inputId = "categorical_variable",
	label = "Select Categorical Variable:",
	choices = Categorical.Variables,
	selected = Categorical.Variables[2]
)
selectInput(
	inputId = "numeric_variable",
	label = "Select Numeric Variable:",
	choices = Numeric.Variables,
	selected = Numeric.Variables[2]
)
```

## Row

### **Histogram**

```{r, message=FALSE}
renderPlotly({
p2 <- ggplot(data = data, 
	aes_string(
		x = input$numeric_variable,
		fill = data$Attrition)) + 
	geom_histogram(bins = 50) + theme + 
    scale_color_manual(values = c("#D2EEEA", "#2A5676")) +
     scale_fill_manual(values = c("#D2EEEA", "#2A5676")) +
	theme(
		legend.position = 'none',
		legend.title = element_blank()
	)
ggplotly(p2)
})
```

## Row

### **Boxplot**

```{r, message=FALSE}
renderHighchart(
highchart() %>%
  hc_xAxis(type ="category")%>%
  hc_add_series_list(data_to_boxplot(data,
								!!sym(input$numeric_variable),
								!!sym(input$categorical_variable),
								group_var = Attrition,
								add_outliers = TRUE)) %>%
  hc_xAxis(title = list(text = "Attrition")) %>% 
  hc_legend(enabled= F) %>% 
	hc_colors(c('#2A5676FF', '#3B809AFF', '#67A9B6FF', '#99CFD1FF', '#D2EEEAFF')) 
)

```

### **Correlation**

```{r correlation}
m = as.matrix((cor(data[, sapply(data, is.numeric)])))

d3heatmap::d3heatmap(m, 
					dendrogram = 'both',
          xaxis_font_size = 5,
					col = grDevices::hcl.colors(5, 
          palette = "Teal"))
```

# Data Analysis {data-navmenu="HR Analytics"}

## Column {.tabset}

### Data Summary {style="position: relative;"}

#### Data Summary

-   **Dataset Structure**: 1470 observations, 35 features.
-   **Missing Data**: there are no missing data.
-   **Data Type**: We only have two datatypes in this dataset: factors and integers. Attrition is the object of interest of our dataset as we would like to find out why employees are leaving the organization.
-   **Imbalanced dataset**: $1237$ ($84%$ of cases) employees did not leave the organization while $237$ ($16%$ of cases) did leave the organization making our dataset to be considered imbalanced.

```{r}
crosstalk::bscols(psych::describe(data) %>% 
										round(3) %>% select(-trimmed, 
																				-skew,-mad,
																				-kurtosis) %>% 
										rownames_to_column() %>%  
										pivot_longer(-rowname) %>% 
										pivot_wider(names_from=rowname,
																values_from=value) %>%
										reactable::reactable(
	highlight = T, outlined = T,
	striped = T, compact = T, 
	wrap = F, fullWidth = T
))
```

#### Analysis of Correlation Matrix:

-   Monthly income is highly correlated with the job level, total working years and age.

-   The percent salary hike has high correlation with the performance rating

### Logistic Regression

The **logistic regression model** is used to model the relationship between a binary target variable, in this case *Attrition*, and a set of independent variables. These independent variables can be either qualitative or quantitative. In logistic regression, the model predicts the logit transformation of the probability of the event.

```{r echo=FALSE, message=FALSE, warning=FALSE,results = 'asis'}
require(caret)
index <- createDataPartition(data$Attrition, 
														 p = .70, list = FALSE)
train <- data[index, ]
test <- data[-index, ]

# Training the model
logistic_model <- glm(Attrition ~ ., family = "binomial", train)

# Checking the model
#summary(logistic_model)
```

The intercept $\beta_0$ was really small, indicating that the odds of the whole population of interest to leave the company are low; however it is important to note that we are dealing with an imbalanced dataset, where the 84% did not turnover.

Taking the exponential of $\beta_i$ coefficients, we get the **odds** that tells us the factors by which odds increase if the independent variable increases by one. These, are reported in the table below among their respective $95\%$ confidence interval:

```{r eval=FALSE, include=FALSE}
#We can convert the log of odds back to simple probabilities by using sigmoid function.
#Sigmoid function, 
exp(-6.598)/(1+exp(-6.598)) #p
exp(-6.598) #odds
```

```{r message=FALSE, warning=FALSE, include=T, results='asis'}
# Table of Coefficients
library(reactable)
#Significant Coefficients
OR <- as.data.frame(round(summary(logistic_model)$coef[summary(logistic_model)$coef[,4] <= .01, 1],3))
colnames(OR)  <- c('OR')
OR <- OR %>% mutate(
	OR = exp(OR),
	OR = round(OR,2)) %>% slice_tail(
		n = (12))

confint <- broom::tidy(
	logistic_model, conf.int = T
) %>% filter(p.value <= 0.01) %>% 
	select(conf.low, conf.high) %>% 
	slice_tail(n = 12) %>%
	round(2)

OR$'CI Low (95%)' <- round(exp(confint$conf.low),2)
OR$'CI High (95%)' <- round(exp(confint$conf.high),2)

table <- OR %>% rownames_to_column("Variable") %>% 
	reactable(
	highlight = T, outlined = T,
	striped = T, compact = T, 
	wrap = F, fullWidth = F, width = 750,
	sortable = T, resizable = T,
	defaultPageSize = 12, showPageInfo = F,
	  theme = reactableTheme(
    borderColor = "#dfe2e5",
    stripedColor = "#f6f8fa",
    highlightColor = "#f0f5f9",
    cellPadding = "8px 12px",
    headerStyle = list(
      "&:hover[aria-sort]" = list(
      	background = "hsl(0, 0%, 96%)"),
      "&[aria-sort='ascending'], &[aria-sort='descending']" = 
      	list(background = "hsl(0, 0%, 96%)"),
      borderColor = "#555")),
	columns = list(
		Variable = colDef(minWidth = 200)
	)
) 
crosstalk::bscols(table)
```

\n

#### Interpretation

Among the factors affecting more the turnover rate, the most important findings are the following:

-   The employees which not work over time are way less expected to leave the company compared to those working over time.
-   The odds of not leaving the company for those who are satisfied with their current jobs increases by 45% compared with those less satisfied. The same applies for those satisfied with the work environment, with an expected increase of the odds of not leaving their current jobs by 67%, similar rate for those who are involved with their current job.
-   Also, the odds of leaving the company increases by 33% for the employees which did not get a promotion in years.

```{r, message=FALSE, warning=FALSE, include=F}
# Odds ratio and 95% CI
round(exp(coef(logistic_model)),3)
```

#### Testing

```{r, message=FALSE, warning=FALSE, include=FALSE}
#I have to specify the columns of the corresponding variables from the var-cov matrix of the model
EducationField = c(13,14,15,16,17) 
Education = c(9,10,11,12)

pacman::p_load(aod)
aod::wald.test(
	b = coef(logistic_model), 
  Sigma = vcov(logistic_model),
	Terms = Education)

aod::wald.test(
	b = coef(logistic_model), 
  Sigma = vcov(logistic_model),
	Terms = EducationField)
```

-   I wanted to investigate the overall effect of the variables *Education* and *Education Field* in the model using a **Wald test**, however the test have not reported important probabilities.
-   Moreover I questioned whether there is an important difference between *Education level 1* and *Education level 5* and the test provided a *p-value* lower than $0.05$

```{r, message=FALSE, warning=FALSE, include=F}
#To contrast these two terms, we multiply one of them by 1, and the other by -1. The other terms in the model are not involved in the test, so they are multiplied by 0.
EducationDiff = c(rep(0,8),1,-1,rep(0,36))
aod::wald.test(
	b = coef(logistic_model), 
  Sigma = vcov(logistic_model),
	Terms = EducationField) #p-value=0.063 < 0.05
```

#### Model Metrics

```{r, message=FALSE, warning=FALSE, include=T, echo=FALSE}
test$pred <- predict(logistic_model, test, type="response")
test$pred_class <- ifelse(test$pred > 0.5, "No", "Yes")
test$pred_class <- as.factor(test$pred_class)
confusionMatrix(test$Attrition, test$pred_class)
```

##### ROC Curve

```{r, message=FALSE}
# The area under the curve(AUC) is the measure that represents ROC(Receiver Operating Characteristic) curve. This ROC curve is a line plot that is drawn between the Sensitivity and (1 â€“ Specificity) Or between TPR and TNR. It can be proven it is equal to the average between sensitivity and specificty
#This graph is then used to generate the AUC value. An AUC value of greater than .70 indicates a good model.
library(pROC)
roc <- roc(train$Attrition, logistic_model$fitted.values, 
					 plot = TRUE, print.auc = TRUE)
```

A good model will have a high AUC, that is as often as possible a high sensitivity and specificity, and this is the case as the Area Under the Curve (AUC) reported a value of $0.87%$

# Table

```{r}
library(toastui)
library(scales)
set_grid_theme(
  row.even.background = "#FFF",
  cell.normal.border = "#448AA1FF",
  cell.normal.showVerticalBorder = TRUE,
  cell.normal.showHorizontalBorder = TRUE,
  cell.header.background = "#2A5676",
  cell.header.text = "#FFF",
  cell.selectedHeader.background = "#2A5676FF",
  cell.focused.border = "#013ADF"
)

datagrid(data %>% select(Attrition, Age, MonthlyIncome,
												 EnvironmentSatisfaction,
												 Gender,MaritalStatus,Department,
												 PercentSalaryHike, DailyRate,
												 DistanceFromHome,EducationField,
												 RelationshipSatisfaction,
												 TotalWorkingYears, everything()), 
				 colwidths = "guess", height = "300px") %>%
  grid_colorbar(
    column = "EnvironmentSatisfaction",
    label_outside = TRUE,
    label_width = "30px",
    bar_bg = "#2A5676",
    color = "#3B809A"
  ) %>%
  grid_style_column(
    column = "DistanceFromHome",
    background = scales::col_numeric(
    	palette = grDevices::hcl.colors(5, rev = T,
    																	palette = "Teal"),
    	domain =c(0,max(DistanceFromHome)+10))(DistanceFromHome),
    fontWeight = "bold",
    color = ifelse(
    	DistanceFromHome > median(data$DistanceFromHome), 
    	"white", "black")
  ) %>% 
	grid_style_column(
		column = "Attrition",
		fontWeight = "bold",
    color = ifelse(
    	Attrition == 'Yes', 
    	"#2A5676", "#a")
	) %>% 
  grid_columns(
  	columns = c("Attrition", "Age"), width = 20) %>% 
	grid_style_column(
		column = "MonthlyIncome",
		fontWeight = "bold") %>% 
  grid_format(
    "PercentSalaryHike", label_dollar(prefix= "",suffix = "%" )
  ) %>%
  grid_format(
    "MonthlyIncome", label_dollar(prefix = "$", big.mark = ",")
  ) %>% 
  grid_format(
    "Gender", function(value) {
      lapply(X = value, FUN = function(x) {
          if (x == 'Male')
            shiny::icon("mars")
          else
            shiny::icon("venus")
      	})}
  )
```
